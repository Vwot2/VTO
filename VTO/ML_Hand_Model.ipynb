{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f249c33-4e73-47d9-b032-1764d4ed6379",
   "metadata": {},
   "source": [
    "## Machine Learning Hand Keypoint Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880fb55-d185-4c77-a00d-2654526b318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import onnx\n",
    "import time\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class HandWristDetector:\n",
    "    def __init__(self, config_path='config.yaml'):\n",
    "        \"\"\"\n",
    "        Initialize HandWristDetector with configuration\n",
    "        \n",
    "        Args:\n",
    "            config_path (str): Path to the configuration YAML file\n",
    "        \"\"\"\n",
    "        with open(config_path, 'r') as f:\n",
    "            self.config = yaml.safe_load(f)\n",
    "        \n",
    "        # Initialize YOLO pose detection model\n",
    "        model_size = self.config['model']['size']\n",
    "        model_path = f\"yolov8{model_size}-pose.pt\"\n",
    "        \n",
    "        # Download model if not exists\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Downloading YOLOv8{model_size} pose model...\")\n",
    "        \n",
    "        self.model = YOLO(model_path)\n",
    "        \n",
    "    def train(self, data_yaml):\n",
    "        \"\"\"\n",
    "        Train the model with custom configuration\n",
    "        \n",
    "        Args:\n",
    "            data_yaml (str): Path to the data YAML file containing dataset configuration\n",
    "            \n",
    "        Returns:\n",
    "            results: Training results object\n",
    "        \"\"\"\n",
    "        # Set training arguments\n",
    "        args = dict(\n",
    "            data=data_yaml,                    # Path to data YAML file\n",
    "            task='pose',                       # Task type for pose detection\n",
    "            mode='train',                      # Training mode\n",
    "            model=self.model,                  # Model to train\n",
    "            epochs=self.config['model']['epochs'],\n",
    "            imgsz=self.config['model']['image_size'],\n",
    "            batch=self.config['model']['batch_size'],\n",
    "            device='',                         # Device to use (auto-select)\n",
    "            workers=8,                         # Number of worker threads\n",
    "            optimizer='AdamW',                  # Optimizer to use (Adam)\n",
    "            patience=20,                       # Early stopping patience\n",
    "            verbose=True,                      # Print verbose output\n",
    "            seed=0,                           # Random seed\n",
    "            deterministic=True,                # Enable deterministic mode\n",
    "            single_cls=True,                   # Single class training\n",
    "            rect=True,                         # Rectangular training\n",
    "            cos_lr=True,                       # Cosine learning rate scheduler\n",
    "            close_mosaic=10,                   # Disable mosaic augmentation for final epochs\n",
    "            resume=False,                      # Resume training\n",
    "            amp=True,                          # Automatic Mixed Precision\n",
    "            \n",
    "            # Learning rate settings\n",
    "            lr0=0.001,                        # Initial learning rate\n",
    "            lrf=0.01,                         # Final learning rate fraction\n",
    "            momentum=0.937,                    # SGD momentum/Adam beta1\n",
    "            weight_decay=0.0005,              # Optimizer weight decay\n",
    "            warmup_epochs=3.0,                # Warmup epochs\n",
    "            warmup_momentum=0.8,              # Warmup initial momentum\n",
    "            warmup_bias_lr=0.1,               # Warmup initial bias learning rate\n",
    "            \n",
    "            # Loss coefficients\n",
    "            box=7.5,                          # Box loss gain\n",
    "            cls=0.5,                          # Class loss gain\n",
    "            pose=12.0,                        # Pose loss gain\n",
    "            kobj=2.0,                         # Keypoint obj loss gain\n",
    "            \n",
    "            # Augmentation settings\n",
    "            degrees=10.0,                      # Rotation degrees\n",
    "            translate=0.2,                    # Translation\n",
    "            scale=0.7,                        # Scale\n",
    "            fliplr=0.5,                       # Horizontal flip probability\n",
    "            mosaic=1.0,                       # Mosaic probability\n",
    "            mixup=0.0,                        # Mixup probability\n",
    "            \n",
    "            # Saving settings\n",
    "            project='runs/pose',              # Project name\n",
    "            name='train',                     # Run name\n",
    "            exist_ok=False,                   # Allow existing project\n",
    "            pretrained=True,                  # Use pretrained model\n",
    "            plots=True,                       # Generate plots\n",
    "            save=True,                        # Save train checkpoints\n",
    "            save_period=-1,                   # Save checkpoint every x epochs\n",
    "            \n",
    "            # Validation settings\n",
    "            val=True,                         # Validate during training\n",
    "            save_json=False,                  # Save JSON validation results\n",
    "            conf=None,                        # Confidence threshold\n",
    "            iou=0.7,                          # NMS IoU threshold\n",
    "            max_det=300,                      # Maximum detections per image\n",
    "            \n",
    "            # Advanced settings\n",
    "            fraction=1.0,                     # Dataset fraction to train on\n",
    "            profile=False,                    # Profile ONNX/TF.js/TensorRT\n",
    "            overlap_mask=True,                # Masks should overlap during inference\n",
    "            mask_ratio=4,                     # Mask downsample ratio\n",
    "            dropout=0.2,                      # Use dropout regularization\n",
    "            label_smoothing=0.1,              # Label smoothing epsilon\n",
    "            nbs=64,                          # Nominal batch size\n",
    "        )\n",
    "        \n",
    "        # Start training\n",
    "        try:\n",
    "            results = self.model.train(**args)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Training error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def evaluate(self, data_yaml):\n",
    "        \"\"\"\n",
    "        Evaluate the model on validation/test set\n",
    "        \n",
    "        Args:\n",
    "            data_yaml (str): Path to the data YAML file\n",
    "            \n",
    "        Returns:\n",
    "            results: Validation results object\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.model.val(\n",
    "                data=data_yaml,\n",
    "                imgsz=self.config['model']['image_size'],\n",
    "                batch=self.config['model']['batch_size'],\n",
    "                conf=0.25,\n",
    "                iou=0.7,\n",
    "                device='',\n",
    "                verbose=True,\n",
    "                save_json=False,\n",
    "                save_hybrid=False,\n",
    "                max_det=300,\n",
    "                half=False\n",
    "            )\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Evaluation error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def export_model(self, format='onnx'):\n",
    "        \"\"\"\n",
    "        Export the model to specified format\n",
    "        \n",
    "        Args:\n",
    "            format (str): Format to export to ('onnx' or 'tflite')\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if format == 'onnx':\n",
    "                self.model.export(\n",
    "                    format='onnx',\n",
    "                    dynamic=True,\n",
    "                    simplify=True,\n",
    "                    opset=11,\n",
    "                    device='cpu'\n",
    "                )\n",
    "            elif format == 'tflite':\n",
    "                self.model.export(\n",
    "                    format='tflite',\n",
    "                    int8=True,\n",
    "                    device='cpu'\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Export error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def predict(self, image_path):\n",
    "        \"\"\"\n",
    "        Run inference on a single image\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the input image\n",
    "            \n",
    "        Returns:\n",
    "            results: Detection results object\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.model.predict(\n",
    "                source=image_path,\n",
    "                conf=0.25,\n",
    "                iou=0.45,\n",
    "                imgsz=self.config['model']['image_size'],\n",
    "                device='',\n",
    "                verbose=False,\n",
    "                save=True,\n",
    "                save_txt=False,\n",
    "                save_conf=False,\n",
    "                save_crop=False,\n",
    "                show_labels=True,\n",
    "                show_conf=True,\n",
    "                max_det=300,\n",
    "                agnostic_nms=False,\n",
    "                classes=None,\n",
    "                retina_masks=False,\n",
    "                boxes=True\n",
    "            )\n",
    "            return results[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def predict_batch(self, image_paths):\n",
    "        \"\"\"\n",
    "        Run inference on a batch of images\n",
    "        \n",
    "        Args:\n",
    "            image_paths (list): List of paths to input images\n",
    "            \n",
    "        Returns:\n",
    "            results: List of detection results objects\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = self.model.predict(\n",
    "                source=image_paths,\n",
    "                conf=0.25,\n",
    "                iou=0.45,\n",
    "                imgsz=self.config['model']['image_size'],\n",
    "                batch=self.config['model']['batch_size']\n",
    "            )\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Batch prediction error: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d6fa8-26e4-4f15-9f5d-abb364a1496f",
   "metadata": {},
   "source": [
    "## Webcam script to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe213e0-6e22-4dbe-ba85-17f133f652d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class WebcamDetector:\n",
    "    def __init__(self, config_path='config.yaml'):\n",
    "        \"\"\"Initialize the webcam detector with configuration\"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.config = self._load_config(config_path)\n",
    "        self.cap = None\n",
    "        self.frame_count = 0\n",
    "        self.fps = 0\n",
    "        self.last_time = time.time()\n",
    "        \n",
    "        # Initialize the hand detector model with custom weights\n",
    "        try:\n",
    "            # Use the last trained weights from your output directory\n",
    "            weights_path = os.path.join(\n",
    "                self.config['paths']['output_dir'],\n",
    "                'runs/pose/train11/weights/best.pt'\n",
    "            )\n",
    "            if not os.path.exists(weights_path):\n",
    "                raise FileNotFoundError(f\"Weights file not found at {weights_path}\")\n",
    "            \n",
    "            self.model = YOLO(weights_path)\n",
    "            self.logger.info(\"Custom hand detection model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _load_config(self, config_path):\n",
    "        \"\"\"Load configuration file\"\"\"\n",
    "        try:\n",
    "            with open(config_path, 'r') as f:\n",
    "                return yaml.safe_load(f)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading config: {e}\")\n",
    "            raise\n",
    "\n",
    "    def initialize_camera(self, camera_id=0):\n",
    "        \"\"\"Initialize the webcam\"\"\"\n",
    "        self.cap = cv2.VideoCapture(camera_id)\n",
    "        if not self.cap.isOpened():\n",
    "            raise ValueError(f\"Could not open camera {camera_id}\")\n",
    "        \n",
    "        # Set camera properties\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 640)\n",
    "        self.logger.info(\"Camera initialized successfully\")\n",
    "\n",
    "    def calculate_fps(self):\n",
    "        \"\"\"Calculate FPS\"\"\"\n",
    "        self.frame_count += 1\n",
    "        if (time.time() - self.last_time) > 1.0:\n",
    "            self.fps = self.frame_count\n",
    "            self.frame_count = 0\n",
    "            self.last_time = time.time()\n",
    "        return self.fps\n",
    "\n",
    "    def draw_detections(self, frame, result):\n",
    "        \"\"\"Draw hand detections and wrist keypoints\"\"\"\n",
    "        annotated_frame = frame.copy()\n",
    "        \n",
    "        if result.keypoints is not None:\n",
    "            keypoints = result.keypoints.data\n",
    "            boxes = result.boxes.data\n",
    "            \n",
    "            for box, kpts in zip(boxes, keypoints):\n",
    "                # Get box coordinates\n",
    "                x1, y1, x2, y2 = map(int, box[:4])\n",
    "                conf = float(box[4])\n",
    "                \n",
    "                # Draw bounding box for hand\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Add confidence score\n",
    "                cv2.putText(annotated_frame, f\"Hand: {conf:.2f}\", \n",
    "                           (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                           0.5, (0, 255, 0), 2)\n",
    "                \n",
    "                # Draw wrist keypoint\n",
    "                for kpt in kpts:\n",
    "                    x, y = map(int, kpt[:2])\n",
    "                    conf = float(kpt[2])\n",
    "                    if conf > 0.5:  # Only draw high-confidence keypoints\n",
    "                        cv2.circle(annotated_frame, (x, y), 5, (255, 0, 0), -1)\n",
    "                        cv2.putText(annotated_frame, f\"Wrist: {conf:.2f}\", \n",
    "                                  (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                  0.5, (255, 0, 0), 2)\n",
    "        \n",
    "        # Add FPS counter\n",
    "        fps = self.calculate_fps()\n",
    "        cv2.putText(annotated_frame, f'FPS: {fps}', (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        return annotated_frame\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process each frame for hand detection\"\"\"\n",
    "        try:\n",
    "            # Run inference\n",
    "            results = self.model.predict(\n",
    "                source=frame,\n",
    "                conf=0.25,  # Confidence threshold\n",
    "                iou=0.45,   # NMS IoU threshold\n",
    "                verbose=False,\n",
    "                stream=True\n",
    "            )\n",
    "            \n",
    "            # Get the first result\n",
    "            result = next(results)\n",
    "            \n",
    "            # Draw detections\n",
    "            annotated_frame = self.draw_detections(frame, result)\n",
    "            \n",
    "            return annotated_frame\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing frame: {e}\")\n",
    "            return frame\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main loop for webcam detection\"\"\"\n",
    "        try:\n",
    "            self.initialize_camera()\n",
    "            \n",
    "            while True:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    self.logger.error(\"Failed to grab frame\")\n",
    "                    break\n",
    "\n",
    "                # Process frame\n",
    "                processed_frame = self.process_frame(frame)\n",
    "                \n",
    "                # Display the frame\n",
    "                cv2.imshow('Hand-Wrist Detection', processed_frame)\n",
    "                \n",
    "                # Break loop on 'q' press\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in webcam detection: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            self.logger.info(\"Webcam detection stopped\")\n",
    "\n",
    "def main():\n",
    "    # Set up logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    \n",
    "    # Initialize and run detector\n",
    "    detector = WebcamDetector()\n",
    "    detector.run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
